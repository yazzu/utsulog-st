import os
import sys
import time
from google import genai
from google.genai import types
from google.genai.types import HttpOptions

def generate_content(input_file, system_instruction_file='system_instruction.txt', wordlist_file='wordlist.txt'):
    # Check if files exist
    if not os.path.exists(input_file):
        print(f"Error: Input file {input_file} not found.")
        return
    if not os.path.exists(system_instruction_file):
        print(f"Error: System instruction file {system_instruction_file} not found.")
        return
    # Save output
    basename = os.path.splitext(os.path.basename(input_file))[0]
    if basename.endswith('_strip'):
            basename = basename[:-6]
    output_file = os.path.join(os.path.dirname(input_file), f"{basename}_fixed.txt")
    if os.path.exists(output_file):
        print(f"Error: Output file {output_file} already exists.")
        return

    # wordlist might be optional or empty, but specified in requirements
    wordlist_content = ""
    if os.path.exists(wordlist_file):
        with open(wordlist_file, 'r', encoding='utf-8') as f:
            wordlist_content = f.read().strip()
    else:
        print(f"Warning: Wordlist file {wordlist_file} not found. Proceeding without it.")

    # Get API Key
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        print("Error: GEMINI_API_KEY environment variable is not set.")
        return

    TIMEOUT_SECONDS = os.environ.get("TIMEOUT_SECONDS")
    if not TIMEOUT_SECONDS:
        print("Warning: TIMEOUT_SECONDS environment variable is not set. Defaulting to 5 minutes.")
        TIMEOUT_SECONDS = 5 * 60 * 1000 # 5 minutes

    # Read Input Content
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            # Assumes input file has lines properly separated. 
            # If input file is previously generated by to_chunk.py, it might contain blank lines.
            lines = [line.rstrip('\n') for line in f if line.strip()]
    except Exception as e:
        print(f"Error reading input file: {e}")
        return

    # Read System Instruction
    try:
        with open(system_instruction_file, 'r', encoding='utf-8') as f:
            system_instruction = f.read()
    except Exception as e:
        print(f"Error reading system instruction file: {e}")
        return

    print("Initializing Gemini Client...")
    client = genai.Client(api_key=api_key, http_options=HttpOptions(timeout=TIMEOUT_SECONDS))

    # Safety settings
    safety_settings = [
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold=types.HarmBlockThreshold.BLOCK_NONE,
        ),
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold=types.HarmBlockThreshold.BLOCK_NONE,
        ),
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
            threshold=types.HarmBlockThreshold.BLOCK_NONE,
        ),
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold=types.HarmBlockThreshold.BLOCK_NONE,
        ),
    ]

    LINES_PER_CHUNK = 2000
    OVERLAP_LINES = 50

    total_lines = len(lines)
    print(f"Total lines to process: {total_lines}")

    fixed_lines_all = []
    
    start_index = 0
    chunk_count = 0

    system_instruction = f"""
{system_instruction}

{wordlist_content}
"""

    while start_index < total_lines:
        chunk_count += 1
        end_index = min(start_index + LINES_PER_CHUNK, total_lines)
        
        current_chunk_lines = lines[start_index:end_index]
        prompt = "\n".join(current_chunk_lines)

        print(f"Processing Chunk {chunk_count}: Lines {start_index+1} to {end_index} ({len(current_chunk_lines)} lines)...")

        print(f"Request sent...")
        start_time = time.time()  # 計測開始
        try:
            response = client.models.generate_content(
                model="gemini-3-flash-preview",
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=1.0,
                    top_p=0.95,
                    top_k=64,
                    system_instruction=system_instruction,
                    safety_settings=safety_settings,
                    response_mime_type="text/plain",
                )
            )
            
            fixed_text = response.text
            # Split response back into lines to handle overlap
            fixed_chunk_lines = fixed_text.strip().split('\n')

            if(len(fixed_chunk_lines) < len(current_chunk_lines)):
                print(f"Warning: Response shorter than input ({len(fixed_chunk_lines)} < {len(current_chunk_lines)}). Truncating.")

            # If not the first chunk, remove the overlap from the BEGINNING of the response
            # because we fed the overlap as context at the beginning of this chunk.
            if chunk_count > 1:
                # We assume the model returns the text corresponding to the input.
                # The first OVERLAP_LINES of the input were context (repeated from prev chunk).
                # ideally the model output for these lines matches the previous output.
                # We just drop them to avoid duplication.
                if len(fixed_chunk_lines) > OVERLAP_LINES:
                    print(f"  Dropping first {OVERLAP_LINES} lines of response (overlap).")
                    fixed_chunk_lines = fixed_chunk_lines[OVERLAP_LINES:]
                else:
                    # Fallback if response is weirdly short
                    print(f"  Warning: Response shorter than overlap length ({len(fixed_chunk_lines)} < {OVERLAP_LINES}). Keeping all.")
            
            fixed_lines_all.extend(fixed_chunk_lines)

        except Exception as e:
            # Using string matching for timeout detection as specific exception classes might vary
            if "timeout" in str(e).lower() or "deadline" in str(e).lower():
                print(f"Error: Request timed out. Exiting with code 75.: {e}")
                sys.exit(75)
            
            print(f"Error during generation for chunk {chunk_count}: {e}")
            # Decide weather to ABORT, CONTINUE, or use original lines?
            # For now, append original lines as fallback or stop? 
            # Let's stop to be safe, or maybe just print error.
            # Ideally we might want to retry. For now, just logging error and returning.
            return
        finally:
            # 成功・失敗に関わらず時間を表示
            end_time = time.time()
            elapsed_time = end_time - start_time
            print(f"Processing time: {elapsed_time:.2f} seconds")

        # Prepare for next loop
        # Next chunk starts at end of this chunk MINUS overlap
        # But wait, the standard logic:
        # If we want to process 0-3000, then 2950-5950...
        # start_index for 2nd chunk should be 2950.
        # Current end_index was 3000.
        # So next start should be end_index - OVERLAP_LINES.
        # BUT only if we haven't reached end.
        
        if end_index == total_lines:
            break

        start_index = end_index - OVERLAP_LINES
        
        # Avoid infinite loop if overlap >= chunk size (not the case here)
        if start_index >= end_index: 
             start_index = end_index # Force progress if config is bad

    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("\n".join(fixed_lines_all))
        
    print(f"Saved fixed text to {output_file} (Total lines: {len(fixed_lines_all)})")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python generate_content.py <input_text_file> [system_instruction_file] [wordlist_file]")
    else:
        input_file = sys.argv[1]
        system_instruction_file = sys.argv[2] if len(sys.argv) > 2 else 'batch_st/system_instruction.txt'
        wordlist_file = sys.argv[3] if len(sys.argv) > 3 else 'batch_st/wordlist.txt'
        generate_content(input_file, system_instruction_file, wordlist_file)
